{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install langchain\n",
    "! pip install langchain_openai\n",
    "! pip install langchain_community\n",
    "! pip install pymongo\n",
    "! pip install python-dotenv\n",
    "! pip install azure-core\n",
    "! pip install azure-cosmos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import openai\n",
    "import pymongo\n",
    "\n",
    "from dotenv import dotenv_values\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "env_name = \"example.env\" \n",
    "config = dotenv_values(env_name)\n",
    "\n",
    "openai.api_type = config['openai_type']\n",
    "# Azure OpenAI connection details\n",
    "openai_endpoint = config['openai_endpoint']\n",
    "openai_key = config['openai_key']\n",
    "openai_version = config['openai_version']\n",
    "openai_embeddings_deployment = config['openai_embeddings_deployment']\n",
    "openai_embeddings_model = config['openai_embeddings_model']\n",
    "openai_embeddings_dimensions = int(config['openai_embeddings_dimensions'])\n",
    "openai_completions_deployment = config['openai_completions_deployment']\n",
    "openai_completions_model = config['openai_completions_model']\n",
    "cosmos_vector_property = config['cosmos_vector_property_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connection string\n",
    "mongo_conn = config['mongo_vcore_connection_string']\n",
    "mongo_client = pymongo.MongoClient(mongo_conn)\n",
    "\n",
    "# Database name\n",
    "DATABASE_NAME = \"ResturantChain\"\n",
    "db = mongo_client[DATABASE_NAME]\n",
    "\n",
    "# Drop the database if it already exists (consider if this is really needed, as it will remove all existing data)\n",
    "#mongo_client.drop_database(DATABASE_NAME)\n",
    "\n",
    "# Collection names\n",
    "collection_names = [\"Contoso\", \"Contoso West\", \"Users\"]\n",
    "\n",
    "# Iterate through the collection names and create them if they do not exist\n",
    "for collection_name in collection_names:\n",
    "    if collection_name not in db.list_collection_names():\n",
    "        # Creates a collection\n",
    "        db.create_collection(collection_name)\n",
    "        print(f\"Created collection '{collection_name}'.\")\n",
    "    else:\n",
    "        print(f\"Using existing collection: '{collection_name}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.command({\n",
    "  'createIndexes': 'FoodCollection',\n",
    "  'indexes': [\n",
    "    {\n",
    "      'name': 'vectorSearchIndex',\n",
    "      'key': {\n",
    "        \"Embedding\": \"cosmosSearch\"\n",
    "      },\n",
    "      'cosmosSearchOptions': {\n",
    "        'kind': 'vector-hnsw',\n",
    "        'm': 16,\n",
    "        'efConstruction': 40,\n",
    "        'similarity': 'COS',\n",
    "        'dimensions': 1536\n",
    "      }\n",
    "    }\n",
    "  ]\n",
    "});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "\n",
    "data_file = open(file=\"./data/results.json\", mode=\"r\") \n",
    "data = json.load(data_file)\n",
    "data_file.close()\n",
    "vcore_collection = db['FoodCollection']\n",
    "result = vcore_collection.insert_many(data)\n",
    "\n",
    "print(f\"Number of data points added: {len(result.inserted_ids)} in {vcore_collection.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "\n",
    "azure_openai_embeddings = AzureOpenAIEmbeddings(\n",
    "    azure_deployment = openai_embeddings_deployment,\n",
    "    api_key= openai_key,\n",
    "    azure_endpoint= openai_endpoint,\n",
    "    model= openai_embeddings_model,\n",
    "    dimensions= openai_embeddings_dimensions,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Khelan Modi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain_core\\utils\\utils.py:161: UserWarning: WARNING! azure_endpoint is not default parameter.\n",
      "                azure_endpoint was transferred to model_kwargs.\n",
      "                Please confirm that azure_endpoint is what you intended.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "create_retrieval_chain() got an unexpected keyword argument 'prompt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 65\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m demo_interface\n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m# Prepare the chain and setup the demo\u001b[39;00m\n\u001b[1;32m---> 65\u001b[0m food_ordering_system \u001b[38;5;241m=\u001b[39m \u001b[43mprepare_food_ordering_system\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m    \u001b[49m\u001b[43mazure_endpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopenai_endpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m    \u001b[49m\u001b[43mopenai_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopenai_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcosmos_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmongo_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m    \u001b[49m\u001b[43mazure_openai_embeddings\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mazure_openai_embeddings\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;66;03m# Launch the Gradio interface\u001b[39;00m\n\u001b[0;32m     73\u001b[0m food_ordering_demo \u001b[38;5;241m=\u001b[39m setup_gradio_interface(food_ordering_system)\n",
      "Cell \u001b[1;32mIn[36], line 45\u001b[0m, in \u001b[0;36mprepare_food_ordering_system\u001b[1;34m(azure_endpoint, openai_key, cosmos_conn, azure_openai_embeddings)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# Setup retrieval chain\u001b[39;00m\n\u001b[0;32m     44\u001b[0m retriever \u001b[38;5;241m=\u001b[39m vector_search\u001b[38;5;241m.\u001b[39mas_retriever(search_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msimilarity\u001b[39m\u001b[38;5;124m\"\u001b[39m, search_kwargs\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mk\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m5\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscore_threshold\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0.2\u001b[39m})\n\u001b[1;32m---> 45\u001b[0m retrieval_chain \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_retrieval_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretriever\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchatbot_prompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_source_documents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m retrieval_chain\n",
      "\u001b[1;31mTypeError\u001b[0m: create_retrieval_chain() got an unexpected keyword argument 'prompt'"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains.retrieval import create_retrieval_chain\n",
    "from langchain.vectorstores.azure_cosmos_db import AzureCosmosDBVectorSearch\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "import gradio as gr\n",
    "\n",
    "# Define the food ordering template\n",
    "order_prompt_template = \"\"\"\n",
    "Hello! You can ask me for food recommendations or customize your order according to your dietary preferences.\n",
    "\n",
    "{chat_history},\n",
    "\n",
    "Question: {question}\n",
    "If you don't know what you want yet, feel free to ask for recommendations!\n",
    "\"\"\"\n",
    "\n",
    "# Create a Langchain chatbot prompt template\n",
    "chatbot_prompt = ChatPromptTemplate(\n",
    "    template=order_prompt_template,\n",
    "    messages=[],\n",
    "    input_variables=[\"question\", \"chat_history\"]\n",
    ")\n",
    "\n",
    "def prepare_food_ordering_system(azure_endpoint, openai_key, cosmos_conn, azure_openai_embeddings):\n",
    "    # Initialize the LangChain LLM for chat\n",
    "    llm = ChatOpenAI(\n",
    "        azure_endpoint=azure_endpoint,\n",
    "        api_key=openai_key,\n",
    "        cache=True,\n",
    "        n=1\n",
    "    )\n",
    "    \n",
    "    # Setup Azure CosmosDB Vector Search\n",
    "    vector_search = AzureCosmosDBVectorSearch.from_connection_string(\n",
    "        connection_string=cosmos_conn,\n",
    "        namespace=\"RestaurantChain.FoodCollection\",\n",
    "        text_key=\"description\", \n",
    "        embedding = azure_openai_embeddings,\n",
    "        embedding_key = cosmos_vector_property,\n",
    "    )\n",
    "    \n",
    "    # Setup retrieval chain\n",
    "    retriever = vector_search.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 5, 'score_threshold': 0.2})\n",
    "    retrieval_chain = create_retrieval_chain(llm, retriever, prompt=chatbot_prompt, return_source_documents=False)\n",
    "\n",
    "    return retrieval_chain\n",
    "\n",
    "# Setup Gradio interface for the food ordering system\n",
    "def setup_gradio_interface(chain):\n",
    "    def fetch_response(question, chat_history):\n",
    "        response = chain.invoke({\"question\": question, \"chat_history\": chat_history})\n",
    "        return response['answer'], chat_history + [question + \" - \" + response['answer']]\n",
    "    \n",
    "    with gr.Blocks() as demo_interface:\n",
    "        chatbot = gr.Chatbot(label=\"Food Ordering System\")\n",
    "        msg = gr.Textbox(label=\"Your question\")\n",
    "        chat_history = gr.State([])\n",
    "        \n",
    "        msg.submit(fetch_response, inputs=[msg, chat_history], outputs=[chatbot, chat_history])\n",
    "    \n",
    "    return demo_interface\n",
    "\n",
    "# Prepare the chain and setup the demo\n",
    "food_ordering_system = prepare_food_ordering_system(\n",
    "    azure_endpoint=openai_endpoint,\n",
    "    openai_key=openai_key,\n",
    "    cosmos_conn=mongo_conn,\n",
    "    azure_openai_embeddings = azure_openai_embeddings\n",
    ")\n",
    "\n",
    "# Launch the Gradio interface\n",
    "food_ordering_demo = setup_gradio_interface(food_ordering_system)\n",
    "food_ordering_demo.launch()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
