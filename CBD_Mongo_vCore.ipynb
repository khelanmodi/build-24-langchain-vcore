{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install the Required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langchain\n",
    "%pip install langchain_openai\n",
    "%pip install langchain_community\n",
    "%pip install pymongo\n",
    "%pip install python-dotenv\n",
    "%pip install azure-core\n",
    "%pip install azure-cosmos\n",
    "%pip install jq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U gradio\n",
    "%pip install ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the environment variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the environment variables .env file\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize the OpenAI client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "openai.api_type = os.getenv(\"OPENAI_API_TYPE\", \"azure\")\n",
    "openai.api_base = os.getenv(\"AZURE_OPENAI_ENDPOINT\", \"https://<YOUR-OPENAI-DEPLOYMENT-NAME>.openai.azure.com/\")\n",
    "openai.api_version = os.getenv(\"OPENAI_API_VERSION\", \"2023-09-15-preview\")\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\", \"<YOUR-DEPLOYMENT-KEY>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Database and Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_51544/3751020075.py:5: UserWarning: You appear to be connected to a CosmosDB cluster. For more information regarding feature compatibility and support please visit https://www.mongodb.com/supportability/cosmosdb\n",
      "  mongo_client = MongoClient(mongo_connection_string)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using existing collection: 'Contoso'.\n",
      "Using existing collection: 'Contoso West'.\n",
      "Using existing collection: 'Users'.\n"
     ]
    }
   ],
   "source": [
    "from pymongo import MongoClient\n",
    "\n",
    "# Connection string\n",
    "mongo_connection_string = os.getenv(\"AZURE_COSMOS_CONNECTION_STRING\", \"<YOUR-COSMOS-DB-CONNECTION-STRING>\")\n",
    "mongo_client = MongoClient(mongo_connection_string)\n",
    "\n",
    "# Database name\n",
    "db_name = os.getenv(\"AZURE_COSMOS_DATABASE_NAME\", \"ResturantChain\")\n",
    "db = mongo_client[db_name]\n",
    "\n",
    "# Drop the database if it already exists (consider if this is really needed, as it will remove all existing data)\n",
    "#mongo_client.drop_database(DATABASE_NAME)\n",
    "\n",
    "# Collection names\n",
    "collection_names = [\"Contoso\", \"Contoso West\", \"Users\"]\n",
    "\n",
    "# Iterate through the collection names and create them if they do not exist\n",
    "for collection_name in collection_names:\n",
    "    if collection_name not in db.list_collection_names():\n",
    "        # Creates a collection\n",
    "        db.create_collection(collection_name)\n",
    "        print(f\"Created collection '{collection_name}'.\")\n",
    "    else:\n",
    "        print(f\"Using existing collection: '{collection_name}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders.json_loader import JSONLoader\n",
    "\n",
    "SOURCE_FILE_NAME = \"./data/results.json\"\n",
    "\n",
    "loader = JSONLoader(file_path=SOURCE_FILE_NAME, jq_schema=\".[].description\", text_content=False)\n",
    "json_data = loader.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Berries n kale, strawberries, bananas, blueberries kale, tropical fruit blend, and dragon fruit. Our fruity tasty smoothies are blended to perfection.' metadata={'source': '/workspaces/build-24-langchain-vcore/data/results.json', 'seq_num': 2}\n"
     ]
    }
   ],
   "source": [
    "print(json_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "\n",
    "openai_embeddings_model = os.getenv(\"AZURE_OPENAI_EMBEDDINGS_MODEL_NAME\")\n",
    "openai_embeddings_deployment = os.getenv(\"AZURE_OPENAI_EMBEDDINGS_DEPLOYMENT_NAME\")\n",
    "\n",
    "azure_openai_embeddings: AzureOpenAIEmbeddings = AzureOpenAIEmbeddings(\n",
    "    model=openai_embeddings_model,\n",
    "    azure_deployment=openai_embeddings_deployment,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores.azure_cosmos_db import AzureCosmosDBVectorSearch\n",
    "\n",
    "collection = db[\"FoodCollection\"]\n",
    "index_name = os.getenv(\"AZURE_COSMOS_INDEX_NAME\")\n",
    "\n",
    "vector_store: AzureCosmosDBVectorSearch = AzureCosmosDBVectorSearch.from_documents(\n",
    "    json_data[0:100],\n",
    "    azure_openai_embeddings,\n",
    "    collection=collection,\n",
    "    index_name=index_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'raw': {'defaultShard': {'numIndexesBefore': 1,\n",
       "   'numIndexesAfter': 2,\n",
       "   'createdCollectionAutomatically': False,\n",
       "   'ok': 1}},\n",
       " 'ok': 1}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.vectorstores.azure_cosmos_db import (\n",
    "    CosmosDBSimilarityType,\n",
    "    CosmosDBVectorSearchType,\n",
    ")\n",
    "\n",
    "# Read more about these variables in detail here. https://learn.microsoft.com/en-us/azure/cosmos-db/mongodb/vcore/vector-search\n",
    "num_lists = 100\n",
    "dimensions = 1536\n",
    "similarity_algorithm = CosmosDBSimilarityType.COS\n",
    "kind = CosmosDBVectorSearchType.VECTOR_IVF\n",
    "m = 16\n",
    "ef_construction = 64\n",
    "ef_search = 40\n",
    "score_threshold = 0.1\n",
    "\n",
    "vector_store.create_index(\n",
    "    num_lists, dimensions, similarity_algorithm, kind, m, ef_construction\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prime beef blend, bacon onion compote, gorgonzola, gruyere, and arugula. With chips or eggplant fries.\n"
     ]
    }
   ],
   "source": [
    "query = \"Beef Bacon\"\n",
    "docs = vector_store.similarity_search(query)\n",
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "openai_chat_model = os.getenv(\"AZURE_OPENAI_CHAT_MODEL_NAME\")\n",
    "openai_chat_deployment= os.getenv(\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\")\n",
    "\n",
    "azure_openai_chat: AzureChatOpenAI = AzureChatOpenAI(\n",
    "    model=openai_chat_model,\n",
    "    azure_deployment=openai_chat_deployment,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why did the tomato turn red?\n",
      "\n",
      "Because it saw the salad dressing!\n"
     ]
    }
   ],
   "source": [
    "# Test the chat\n",
    "chat_response = azure_openai_chat.invoke(\"Tell me a joke\")\n",
    "print(chat_response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_prompt=\"\"\"\n",
    "Hello! You can ask me for food recommendations or customize your order according to your preferences.\n",
    "{chat_history},\n",
    "Question: {question}\n",
    "If you don't know what you want yet, feel free to ask for recommendations!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "ORDER_PROMPT_TEMPLATE = PromptTemplate.from_template(order_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "retriever = vector_store.as_retriever(search_type=\"similarity\", search_kwargs={\"k\":1})\n",
    "\n",
    "rag_chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm=azure_openai_chat,\n",
    "    retriever=retriever,\n",
    "    condense_question_prompt=ORDER_PROMPT_TEMPLATE,\n",
    "    return_source_documents=False,\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beef bacon is a type of bacon that is made from beef instead of pork. It is usually made from beef belly, and is cured and smoked in a similar way to pork bacon.\n"
     ]
    }
   ],
   "source": [
    "question = \"What is beef bacon?\"\n",
    "chat_history = []\n",
    "response = rag_chain.invoke({\"question\": question, \"chat_history\": chat_history})\n",
    "print(response['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history.append((question, response['answer']))\n",
    "question = \"Can you tell me more about it?\"\n",
    "response = rag_chain.invoke({\"question\": question, \"chat_history\": chat_history})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What are some dishes that use beef bacon?\n"
     ]
    }
   ],
   "source": [
    "print(response['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "\n",
    "def setup_gradio_interface(chain):    \n",
    "    with gr.Blocks() as demo_interface:\n",
    "        chatbot = gr.Chatbot(label=\"Food Ordering System\")\n",
    "        chat_history = gr.State([])\n",
    "        lc_chat_history = gr.State([])\n",
    "        msg = gr.Textbox(label=\"Your question\")\n",
    "        gr.ClearButton([msg, chatbot])\n",
    "  \n",
    "        def fetch_response(message, chat_history, lc_chat_history):\n",
    "            response = chain.invoke({\"question\": message, \"chat_history\": lc_chat_history})\n",
    "            lc_chat_history.append((message, response['answer']))\n",
    "            chat_history.append([message, response[\"answer\"]])\n",
    "            return \"\", chat_history, lc_chat_history\n",
    "\n",
    "        msg.submit(fetch_response, inputs=[msg, chatbot, lc_chat_history], outputs=[msg, chatbot, lc_chat_history])\n",
    "    \n",
    "    return demo_interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7900\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7900/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bad pipe message: %s [b'\\nUser-Agent: Mozilla/5.0 (Windows NT 10.0; Win6', b' x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome', b'24.0.0.0 Safari/537.36 Edg/124.0.0.0\\r\\nAccept-E', b'oding: gzip, deflate, br, zstd\\r\\nAccept-Language: en-US, en; q=0.9\\r\\nCookie: _gid=GA1.2.1090558647.1715348779; ', b'a_R1FN4KJKJH=GS1.1.1715353577.2.1.1715357100.0.0.0\\r\\nOrigin: https://localhost:7900\\r\\nReferer: h', b'ps://zany-space-funicular-rwgwpqp4qx7h5x7p-7900.app.github.dev/\\r\\nX-Request-ID: 1681b918647424809f6bb35387a5980b\\r\\nX-']\n",
      "Bad pipe message: %s [b'al-IP: 10.240.2.100\\r\\nX-Forwarded-Port: 443\\r\\nX-Forwarded-Scheme: https\\r\\nX-Original', b'RI: /assets/index-D6iiusuW.js\\r\\nX-Scheme: htt', b'\\r\\nsec-ch-ua: \"Chromium\";v=\"124\", \"Microsoft Edge\";v=\"124\", \"Not-A.Brand\";v=\"99\"\\r\\nsec-ch-ua-mobile: ?0\\r\\nsec-ch-u', b'platform: \"Windows\"\\r\\nsec-fetch-site: same-origin\\r\\nsec-fetch-mode: cors\\r\\nsec-fetch-dest: script\\r\\n', b'iority: u=1\\r\\nx-original-proto: https\\r\\nX-Forwarded-Proto: https\\r\\nX-Forwarded-Host: zany-space-funicular-rwgwpqp4']\n"
     ]
    }
   ],
   "source": [
    "food_ordering_demo = setup_gradio_interface(rag_chain)\n",
    "food_ordering_demo.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
