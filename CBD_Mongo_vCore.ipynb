{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install the Required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langchain\n",
    "%pip install langchain_openai\n",
    "%pip install pymongo\n",
    "%pip install jq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the environment variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create .env file if it doesn't exist\n",
    "%cp -n .env.example .env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the environment variables from .env file\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize the OpenAI client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the `api_type`, `api_base`, `api_version`, and `api_key` as global variables to avoid the need to supply them later in code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "openai.api_type = os.getenv(\"OPENAI_API_TYPE\", \"azure\")\n",
    "openai.api_base = os.getenv(\"AZURE_OPENAI_ENDPOINT\", \"https://<YOUR-OPENAI-DEPLOYMENT-NAME>.openai.azure.com/\")\n",
    "openai.api_version = os.getenv(\"OPENAI_API_VERSION\", \"2023-09-15-preview\")\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\", \"<YOUR-DEPLOYMENT-KEY>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intialize the MongoDB Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14191/3844535710.py:5: UserWarning: You appear to be connected to a CosmosDB cluster. For more information regarding feature compatibility and support please visit https://www.mongodb.com/supportability/cosmosdb\n",
      "  mongo_client = MongoClient(mongo_connection_string)\n"
     ]
    }
   ],
   "source": [
    "from pymongo import MongoClient\n",
    "\n",
    "# Connection string\n",
    "mongo_connection_string = os.getenv(\"AZURE_COSMOS_CONNECTION_STRING\", \"<YOUR-COSMOS-DB-CONNECTION-STRING>\")\n",
    "mongo_client = MongoClient(mongo_connection_string)\n",
    "\n",
    "# Database name\n",
    "db_name = os.getenv(\"AZURE_COSMOS_DATABASE_NAME\", \"DatabaseName\")\n",
    "db = mongo_client[db_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data from a JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders.json_loader import JSONLoader\n",
    "\n",
    "SOURCE_FILE_NAME = \"./data/results.json\"\n",
    "\n",
    "loader = JSONLoader(file_path=SOURCE_FILE_NAME, jq_schema=\".[]\", text_content=False)\n",
    "json_data = loader.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='{\"category\": \"Smoothies\", \"name\": \"Jimmy Jam Smoothie\", \"description\": \"Berries n kale, strawberries, bananas, blueberries kale, tropical fruit blend, and dragon fruit. Our fruity tasty smoothies are blended to perfection.\", \"price\": \"5.49 USD\"}' metadata={'source': '/workspaces/build-24-langchain-vcore/data/results.json', 'seq_num': 2}\n"
     ]
    }
   ],
   "source": [
    "# Display a sample from the data\n",
    "print(json_data[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize the Embeddings Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "\n",
    "openai_embeddings_model = os.getenv(\"AZURE_OPENAI_EMBEDDINGS_MODEL_NAME\")\n",
    "openai_embeddings_deployment = os.getenv(\"AZURE_OPENAI_EMBEDDINGS_DEPLOYMENT_NAME\")\n",
    "\n",
    "azure_openai_embeddings: AzureOpenAIEmbeddings = AzureOpenAIEmbeddings(\n",
    "    model=openai_embeddings_model,\n",
    "    azure_deployment=openai_embeddings_deployment,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate and Save Embeddings to MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores.azure_cosmos_db import AzureCosmosDBVectorSearch\n",
    "\n",
    "collection_name = os.getenv(\"AZURE_COSMOS_COLLECTION_NAME\", \"collectionName\")\n",
    "index_name = os.getenv(\"AZURE_COSMOS_INDEX_NAME\", \"indexName\")\n",
    "\n",
    "collection = db[collection_name]\n",
    "\n",
    "# Create embeddings from the data, save to the database and return a connection to MongoDB vCore\n",
    "vector_store: AzureCosmosDBVectorSearch = AzureCosmosDBVectorSearch.from_documents(\n",
    "    json_data[0:100],\n",
    "    azure_openai_embeddings,\n",
    "    collection=collection,\n",
    "    index_name=index_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Vector HNSW Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'raw': {'defaultShard': {'numIndexesBefore': 1,\n",
       "   'numIndexesAfter': 2,\n",
       "   'createdCollectionAutomatically': False,\n",
       "   'ok': 1}},\n",
       " 'ok': 1}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.vectorstores.azure_cosmos_db import (\n",
    "    CosmosDBSimilarityType,\n",
    "    CosmosDBVectorSearchType,\n",
    ")\n",
    "\n",
    "# Read more about these variables in detail here. https://learn.microsoft.com/en-us/azure/cosmos-db/mongodb/vcore/vector-search\n",
    "num_lists = 100\n",
    "dimensions = 1536\n",
    "similarity_algorithm = CosmosDBSimilarityType.COS\n",
    "kind = CosmosDBVectorSearchType.VECTOR_HNSW\n",
    "m = 16\n",
    "ef_construction = 64\n",
    "\n",
    "# Create the collection and the index\n",
    "vector_store.create_index(\n",
    "    num_lists, dimensions, similarity_algorithm, kind, m, ef_construction\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Vector Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"category\": \"Sandwiches\", \"name\": \"Bacon Turkey Bravo Sandwich\", \"description\": \"Whole (1010 Cal.), Half (500 Cal.) Oven-roasted turkey breast raised without antibiotics, Applewood-smoked bacon, smoked Gouda, emerald greens, vine-ripened tomatoes, signature sauce , salt and pepper on Tomato Basil Bread. Allergens: Contains Wheat, Milk, Egg\", \"price\": \"8.79 USD\"}\n"
     ]
    }
   ],
   "source": [
    "query = \"Beef Bacon\"\n",
    "docs = vector_store.similarity_search(query)\n",
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize the Chat Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "openai_chat_model = os.getenv(\"AZURE_OPENAI_CHAT_MODEL_NAME\")\n",
    "openai_chat_deployment= os.getenv(\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\")\n",
    "\n",
    "azure_openai_chat: AzureChatOpenAI = AzureChatOpenAI(\n",
    "    model=openai_chat_model,\n",
    "    azure_deployment=openai_chat_deployment,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why did the tomato turn red? Because it saw the salad dressing!\n"
     ]
    }
   ],
   "source": [
    "# Test the chat\n",
    "chat_response = azure_openai_chat.invoke(\"Tell me a joke\")\n",
    "print(chat_response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the RAG Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_prompt=\"\"\"Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question.\n",
    "\n",
    "Chat History:\n",
    "{chat_history}\n",
    "Follow Up Input: {question}\n",
    "Standalone question:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "ORDER_PROMPT_TEMPLATE = PromptTemplate.from_template(order_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "retriever = vector_store.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 5, 'score_threshold': 0.2})\n",
    "\n",
    "rag_chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm=azure_openai_chat,\n",
    "    retriever=retriever,\n",
    "    condense_question_prompt=ORDER_PROMPT_TEMPLATE,\n",
    "    return_source_documents=False,\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test RAG Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm sorry, there are a few smoothies with strawberries in the description. Which one would you like more information about? \n",
      "- Jimmy Jam Smoothie\n",
      "- Aw Shuckie Shuckie Now Smoothie\n",
      "- Ashunti`Way Smoothie\n"
     ]
    }
   ],
   "source": [
    "question = \"recommend me a strawberry smoothi\"\n",
    "chat_history = []\n",
    "response = rag_chain.invoke({\"question\": question, \"chat_history\": chat_history})\n",
    "print(response['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history.append((question, response['answer']))\n",
    "question = \"What did I just ask you about?\"\n",
    "response = rag_chain.invoke({\"question\": question, \"chat_history\": chat_history})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are two smoothies that include strawberries in their description: the Jimmy Jam Smoothie and the Aw Shuckie Shuckie Now Smoothie.\n"
     ]
    }
   ],
   "source": [
    "print(response['answer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test with Gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install ipywidgets gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "\n",
    "def setup_gradio_interface(chain):    \n",
    "    with gr.Blocks() as demo_interface:\n",
    "        chatbot = gr.Chatbot(label=\"Food Ordering System\")\n",
    "        chat_history = gr.State([])\n",
    "        lc_chat_history = gr.State([])\n",
    "        msg = gr.Textbox(label=\"Your question\")\n",
    "        gr.ClearButton([msg, chatbot])\n",
    "  \n",
    "        def fetch_response(message, chat_history, lc_chat_history):\n",
    "            response = chain.invoke({\"question\": message, \"chat_history\": lc_chat_history})\n",
    "            lc_chat_history.append((message, response['answer']))\n",
    "            chat_history.append([message, response[\"answer\"]])\n",
    "            return \"\", chat_history, lc_chat_history\n",
    "\n",
    "        msg.submit(fetch_response, inputs=[msg, chatbot, lc_chat_history], outputs=[msg, chatbot, lc_chat_history])\n",
    "    \n",
    "    return demo_interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "food_ordering_demo = setup_gradio_interface(rag_chain)\n",
    "food_ordering_demo.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
